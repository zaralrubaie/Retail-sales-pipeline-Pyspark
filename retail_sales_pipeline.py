# -*- coding: utf-8 -*-
"""retail sales pipeline

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15sN8-EEpe8QLSud5wL_mgGbEZlxNdhcI
"""

# Install Java
!apt-get install openjdk-11-jdk-headless -qq > /dev/null

# Set JAVA_HOME
import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-11-openjdk-amd64"

# Install PySpark
!pip install -q pyspark

from pyspark.sql import SparkSession
from pyspark.sql.functions import col,sum
spark = SparkSession.builder \
    .appName("MySparkProject") \
    .getOrCreate()
df=spark.read.csv('/content/retail_sales_dataset.csv',header=True, inferSchema=True)
df.show()

df.printSchema()

df.count()

df.describe().show()

df.select([sum(col(c).isNull().cast("int")).alias(c) for c in df.columns]).show()

df=df.drop('Customer ID','Transaction ID')

from pyspark.sql.functions import col, sum, avg, count, month, year, dayofweek, when,lit
df = df.withColumn("Date", col("Date").cast("timestamp"))
df = df.withColumn("Year", year(col("Date"))) \
       .withColumn("Month", month(col("Date"))) \
       .withColumn("DayOfWeek", dayofweek(col("Date")))  # 1=Sunday, 7=Saturday

df = df.withColumn(
    "AgeGroup",
    when(col("Age") < 18, "<18")
    .when((col("Age") >= 18) & (col("Age") < 30), "18-29")
    .when((col("Age") >= 30) & (col("Age") < 50), "30-49")
    .otherwise("50+")
)

df = df.withColumn("HighQuantityFlag", when(col("Quantity") > 10, 1).otherwise(0))

df=df.drop('Date')

# -----------------------------
# 1️⃣ Imports
# -----------------------------
from pyspark.sql import SparkSession
from pyspark.sql.functions import log1p, expm1, col
from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler
from pyspark.ml.regression import GBTRegressor
from pyspark.ml.evaluation import RegressionEvaluator

# -----------------------------
# 4️⃣ Log-transform target
# -----------------------------
df = df.withColumn("LogTotalAmount", log1p(col("Total Amount")))

# -----------------------------
# 5️⃣ Encode categorical columns
# -----------------------------
categorical_cols = ["Gender", "Product Category", "AgeGroup"]  # skip QuantityGroup

indexers = [StringIndexer(inputCol=c, outputCol=c + "Index") for c in categorical_cols]

encoder = OneHotEncoder(
    inputCols=[c + "Index" for c in categorical_cols],
    outputCols=[c + "Vec" for c in categorical_cols]
)

# -----------------------------
# 6️⃣ Assemble features
# -----------------------------
numeric_cols = ["Age", "Quantity", "Price per Unit", "Year", "Month", "DayOfWeek", "HighQuantityFlag"]
encoded_cols = [c + "Vec" for c in categorical_cols]

feature_cols = numeric_cols + encoded_cols

assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
scaler = StandardScaler(inputCol="features", outputCol="scaledFeatures")

# -----------------------------
# 7️⃣ GBT Regressor
# -----------------------------
gbt = GBTRegressor(featuresCol="scaledFeatures", labelCol="LogTotalAmount", maxIter=200, maxDepth=8)

# -----------------------------
# 8️⃣ Create pipeline
# -----------------------------
pipeline = Pipeline(stages=indexers + [encoder, assembler, scaler, gbt])

# -----------------------------
# 9️⃣ Train/test split
# -----------------------------
train_df, test_df = df.randomSplit([0.7, 0.3], seed=42)

# -----------------------------
# 10️⃣ Fit pipeline
# -----------------------------
model = pipeline.fit(train_df)

# -----------------------------
# 11️⃣ Predictions
# -----------------------------
predictions = model.transform(test_df)

# Convert back from log scale
predictions = predictions.withColumn("prediction_orig", expm1(col("prediction")))

predictions.select("Total Amount", "prediction_orig").show(10)

# -----------------------------
# 12️⃣ Evaluate
# -----------------------------
evaluator = RegressionEvaluator(labelCol="Total Amount", predictionCol="prediction_orig", metricName="rmse")
rmse = evaluator.evaluate(predictions)
print(f"RMSE: {rmse}")

from pyspark.ml.evaluation import RegressionEvaluator

# -----------------------------
# Training predictions
# -----------------------------
train_predictions = model.transform(train_df)
train_predictions = train_predictions.withColumn("prediction_orig", expm1(col("prediction")))

# Test predictions
test_predictions = model.transform(test_df)
test_predictions = test_predictions.withColumn("prediction_orig", expm1(col("prediction")))

# Evaluator
evaluator = RegressionEvaluator(labelCol="Total Amount", predictionCol="prediction_orig", metricName="rmse")

train_rmse = evaluator.evaluate(train_predictions)
test_rmse = evaluator.evaluate(test_predictions)

print(f"Train RMSE: {train_rmse}")
print(f"Test RMSE: {test_rmse}")